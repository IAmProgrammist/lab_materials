---
created: 2025-09-04T10:47:04.044+00:00
modified: 2025-09-04T10:59:14.1414+00:00
---
Градиентный спуск, который сочетает в себе [[Основы ИИ/Заметки/Методы градиентного спуска/Пакетный градиентный спуск|пакетный]] и [[Основы ИИ/Заметки/Методы градиентного спуска/Стохастический градиентный спуск|стохастический]] спуски, он называется *минипакетным* или *minibatch*. За один шаг при таком способе может обрабатываться заданное количество элементов, а не все или один.

Пакетный спуск идёт по пути наискорейшего снижения, в то время как стохастический спуск, используя только один элемент из обучающей выборки, не может вычислить шаг для всей выборки сразу. Данное различие можно рассмотреть графически. 

![[Основы ИИ/Заметки/Изображения/Pasted image 20250904135202.png]]

Представим вид сверху этой функции. Крестиком обозначим минимум. 
![[Основы ИИ/Заметки/Изображения/Pasted image 20250904135227.png]]

Поведение пакетного спуска:
![[Основы ИИ/Заметки/Изображения/Pasted image 20250904135310.png]]

Поведение стохастической функции:
![[Основы ИИ/Заметки/Изображения/Pasted image 20250904135338.png]]
Так как параболоид вытянутый, по его дну проходит "овраг" - зона минимума. В зоне оврага шаги будут очень маленькими, но рано или поздно [[Основы ИИ/Заметки/Методы градиентного спуска/Градиентный спуск|градиентный спуск]] достигнет дна. Спуск происходит по линии антиградиента. 

Несмотря на случайный характер движения рядом с точкой экстремума, было доказано, что стохастический градиентный спуск сходится *почти всегда*. 