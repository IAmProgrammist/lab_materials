---
created: 2025-10-02T09:47:26.2626+00:00
modified: 2025-10-02T09:56:23.2323+00:00
---
Это [[Основы ИИ/Заметки/Архитектура нейронных сетей/Перцептрон|перцептрон]], который имеет несколько слоёв.

![[Основы ИИ/Заметки/Изображения/Pasted image 20251002124707.png]]

Многослойные сети позволяют создавать более сложные нелинейные связи между входными данными и результатами. 

На рисунке выше представлена многослойная сеть, состоящая из входного, промежуточного и выходного слоёв. При этом, входной слой не состоит из ячеек в традиционном смысле. 

Здесь для каждой ячейки задан $u_N$. Две входные ячейки $u_1$ и $u_2$. Две скрытые ячейки $u_3$ и $u_4$. Выходная ячейка: $u_5$.

Связи между сетями реализованы как $w_{i,j}$. Например, связь $w_{3,1}$ отображает связь между ячейками $u_1$ и $u_3$. 

Скрытые и выходные ячейки представляют из себя функцию - результат суммирования дополнительно обрабатывается функцией сжатия. Обычно это *сигмоид*. Результат вычисления этой функции выдаётся на выходе из ячейки.

![[Основы ИИ/Заметки/Изображения/Pasted image 20251002125346.png]]


Покажем структуру выходной ячейки
![[Основы ИИ/Заметки/Изображения/Pasted image 20251002125421.png]]

Важно отметить, что функция сигмоида должна быть применена и к скрытому слою. На рисунке выше присутствует уравнение, показывающее сумму уравнения. Функция $f(x)$ показывает результат суммирования. 

